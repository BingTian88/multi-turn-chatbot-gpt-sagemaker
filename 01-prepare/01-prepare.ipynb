{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a99ae50-4191-4f27-9585-d998c08dc4e9",
   "metadata": {},
   "source": [
    "##### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dabb2f1-56e1-4fa5-bfd8-cd21b85c6682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "!pip install torch==1.12.1+cu113\n",
    "!pip install transformers==4.26.1\n",
    "!pip install datasets==2.9.0\n",
    "!pip install pandas==1.5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6369d40b-8f2a-46db-a491-62a110e4d8db",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d90638-0932-49cc-9188-94b97da980d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import DatasetDict\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import transformers \n",
    "import datasets\n",
    "import logging\n",
    "import pandas\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5b603f-225d-42c5-8c30-a16194f5d2f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2536e890-6119-492a-bbd1-c97d3991e33d",
   "metadata": {},
   "source": [
    "##### Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2e9ab5-4d0e-4d52-a75b-b6876a1439d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b1b115-a2b6-4ce8-9a0b-3ba1c309eac7",
   "metadata": {},
   "source": [
    "##### Log versions of dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49483a10-6df3-4f46-b555-4068edadb2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using transformers version: 4.26.1]\n",
      "[Using datasets version: 2.9.0]\n",
      "[Using pandas version: 1.5.3]\n",
      "[Using torch version: 1.12.1+cu113]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using transformers version: {transformers.__version__}]')\n",
    "logger.info(f'[Using datasets version: {datasets.__version__}]')\n",
    "logger.info(f'[Using pandas version: {pandas.__version__}]')\n",
    "logger.info(f'[Using torch version: {torch.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd54762-27d8-4b07-8b33-486eafdb04c0",
   "metadata": {},
   "source": [
    "#### Load GPT-Neo tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97cd90cf-a011-4788-aa08-98f3c6426ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='EleutherAI/gpt-neo-125M', vocab_size=50257, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True)})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "logger.info(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0c24194-1d85-4d1f-8286-144079f4337f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc1cce-f980-409d-aabf-7f809978b0f2",
   "metadata": {},
   "source": [
    "##### Add special tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b35fb4b1-6c0b-4d73-ba34-ecfcfed24811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "special_tokens = {\n",
    "    'bos_token': '<|startoftext|>',\n",
    "    'additional_special_tokens': ['<|speaker-1|>', '<|speaker-2|>', '<|pad|>', '<|mask|>']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad1e7301-cc2f-48e1-b452-10b1d03ccddb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50262"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = tokenizer.add_special_tokens(special_tokens)\n",
    "vocab = tokenizer.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d248514-d058-4675-9daf-f4f8b7440c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='EleutherAI/gpt-neo-125M', vocab_size=50257, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|startoftext|>', 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'additional_special_tokens': ['<|speaker-1|>', '<|speaker-2|>', '<|pad|>', '<|mask|>']})\n"
     ]
    }
   ],
   "source": [
    "logger.info(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb19e327-e72f-46ee-8e83-703779b05bb4",
   "metadata": {},
   "source": [
    "#### Load dialogues dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d17ef6-2db9-460e-ae57-61f7dbe6c010",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi , how are you doing ? i am getting ready to do some cheetah chasing to stay in shape .&lt;&gt;you must be very fast . hunting is one of my favorite hobbies .&lt;&gt;i am ! for my hobby i like to do canning or some whittling .&lt;&gt;i also remodel homes when i am not out bow hunting .&lt;&gt;that is neat . when i was in high school i placed 6th in 100m dash !&lt;&gt;that is awesome . do you have a favorite season or time of year ?&lt;&gt;i do not . but i do have a favorite meat since that is all i eat exclusively .&lt;&gt;what is your favorite meat to eat ?&lt;&gt;i would have to say its prime rib . do you have any favorite foods ?&lt;&gt;i like chicken or macaroni and cheese .&lt;&gt;do you have anything planned for today ? i think i am going to do some canning .&lt;&gt;i am going to watch football . what are you canning ?&lt;&gt;i think i will can some jam . do you also play footfall for fun ?&lt;&gt;if i have time outside of hunting and remodeling homes . which is not much !&lt;&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi , how are you doing today ?&lt;&gt;i am spending time with my 4 sisters what are you up to&lt;&gt;wow , four sisters . just watching game of thrones .&lt;&gt;that is a good show i watch that while drinking iced tea&lt;&gt;i agree . what do you do for a living ?&lt;&gt;i am a researcher i am researching the fact that mermaids are real&lt;&gt;interesting . i am a website designer . pretty much spend all my time on the computer .&lt;&gt;that is cool my mom does the same thing&lt;&gt;that is awesome . i have always had a love for technology .&lt;&gt;tell me more about yourself&lt;&gt;i really enjoy free diving , how about you , have any hobbies ?&lt;&gt;i enjoy hanging with my mother she is my best friend&lt;&gt;that is nice . moms are pretty cool too .&lt;&gt;i am also fascinated with mermaids&lt;&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we all live in a yellow submarine , a yellow submarine . morning !&lt;&gt;hi ! that is a great line for my next stand up .&lt;&gt;lol . i am shy , anything to break the ice , and i am a beatles fan .&lt;&gt;i can tell . i am not , you can see me in some tv shows&lt;&gt;really ? what shows ? i like tv , it makes me forget i do not like my family&lt;&gt;wow , i wish i had a big family . i grew up in a very small town .&lt;&gt;i did too . i do not get along with mine . they have no class .&lt;&gt;just drink some cola with rum and you will forget about them !&lt;&gt;put the lime in the coconut as well . . .&lt;&gt;nah , plain cuba libre , that is what we drank yesterday at the theater .&lt;&gt;i prefer mojitos . watermelon or cucumber .&lt;&gt;those are really yummy too , but not my favorite .&lt;&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi ! i work as a gourmet cook .&lt;&gt;i do not like carrots . i throw them away .&lt;&gt;really . but , i can sing pitch perfect .&lt;&gt;i also cook , and i ride my bike to work .&lt;&gt;great ! i had won an award for spelling bee .&lt;&gt;my contacts can see through what you are trying to sell me .&lt;&gt;okay but i was published in new yorker once&lt;&gt;you better not make any spelling mistakes .&lt;&gt;i have not . i can cook any word you want me to&lt;&gt;what is your ethnicity ? i am white , and my hair is brown .&lt;&gt;i am asian and have no hair .&lt;&gt;i love hairless asians . do you like carrots ?&lt;&gt;i love carrots . i eat carrots like a horse .&lt;&gt;are you male or female ?&lt;&gt;i work as a gourmet cook who also has a pitch perfect voice .&lt;&gt;i doubt that very much . you probably like to scream alone .&lt;&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how are you doing today&lt;&gt;what do you do for career ? i have a ton of hobbies if you are interested !&lt;&gt;i like to watch kids&lt;&gt;i actually play guitar and do a lot of manly things , like welding .&lt;&gt;what do you weld ? houses ?&lt;&gt;everything ! i am actually manly . but i have a secret i am hiding .&lt;&gt;what is your secret that you have&lt;&gt;my parents do not know that i am . . . homosexual .&lt;&gt;how does that feel for you&lt;&gt;makes me secure with my manly hobby skills .&lt;&gt;i bet that it does&lt;&gt;anyway . what do you do ?&lt;&gt;i watch kids for a living&lt;&gt;that is awesome . do you like it ?&lt;&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  dialogue\n",
       "0  hi , how are you doing ? i am getting ready to do some cheetah chasing to stay in shape .<>you must be very fast . hunting is one of my favorite hobbies .<>i am ! for my hobby i like to do canning or some whittling .<>i also remodel homes when i am not out bow hunting .<>that is neat . when i was in high school i placed 6th in 100m dash !<>that is awesome . do you have a favorite season or time of year ?<>i do not . but i do have a favorite meat since that is all i eat exclusively .<>what is your favorite meat to eat ?<>i would have to say its prime rib . do you have any favorite foods ?<>i like chicken or macaroni and cheese .<>do you have anything planned for today ? i think i am going to do some canning .<>i am going to watch football . what are you canning ?<>i think i will can some jam . do you also play footfall for fun ?<>if i have time outside of hunting and remodeling homes . which is not much !<>\n",
       "1                                                                                                                                                                                                 hi , how are you doing today ?<>i am spending time with my 4 sisters what are you up to<>wow , four sisters . just watching game of thrones .<>that is a good show i watch that while drinking iced tea<>i agree . what do you do for a living ?<>i am a researcher i am researching the fact that mermaids are real<>interesting . i am a website designer . pretty much spend all my time on the computer .<>that is cool my mom does the same thing<>that is awesome . i have always had a love for technology .<>tell me more about yourself<>i really enjoy free diving , how about you , have any hobbies ?<>i enjoy hanging with my mother she is my best friend<>that is nice . moms are pretty cool too .<>i am also fascinated with mermaids<>\n",
       "2                                                                                                                                                                                         we all live in a yellow submarine , a yellow submarine . morning !<>hi ! that is a great line for my next stand up .<>lol . i am shy , anything to break the ice , and i am a beatles fan .<>i can tell . i am not , you can see me in some tv shows<>really ? what shows ? i like tv , it makes me forget i do not like my family<>wow , i wish i had a big family . i grew up in a very small town .<>i did too . i do not get along with mine . they have no class .<>just drink some cola with rum and you will forget about them !<>put the lime in the coconut as well . . .<>nah , plain cuba libre , that is what we drank yesterday at the theater .<>i prefer mojitos . watermelon or cucumber .<>those are really yummy too , but not my favorite .<>\n",
       "3                                                                                                                                                                         hi ! i work as a gourmet cook .<>i do not like carrots . i throw them away .<>really . but , i can sing pitch perfect .<>i also cook , and i ride my bike to work .<>great ! i had won an award for spelling bee .<>my contacts can see through what you are trying to sell me .<>okay but i was published in new yorker once<>you better not make any spelling mistakes .<>i have not . i can cook any word you want me to<>what is your ethnicity ? i am white , and my hair is brown .<>i am asian and have no hair .<>i love hairless asians . do you like carrots ?<>i love carrots . i eat carrots like a horse .<>are you male or female ?<>i work as a gourmet cook who also has a pitch perfect voice .<>i doubt that very much . you probably like to scream alone .<>\n",
       "4                                                                                                                                                                                                                                                                                                                                                                    how are you doing today<>what do you do for career ? i have a ton of hobbies if you are interested !<>i like to watch kids<>i actually play guitar and do a lot of manly things , like welding .<>what do you weld ? houses ?<>everything ! i am actually manly . but i have a secret i am hiding .<>what is your secret that you have<>my parents do not know that i am . . . homosexual .<>how does that feel for you<>makes me secure with my manly hobby skills .<>i bet that it does<>anyway . what do you do ?<>i watch kids for a living<>that is awesome . do you like it ?<>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/dialogues.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7c14f3e-c801-4b98-94f1-e4e4f10bc6df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dialogue    8939\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b2f353-281b-4f70-8e78-81b5b84837dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dialogues = df['dialogue'].tolist()\n",
    "SEP = '<>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c979d9a1-a4ed-4709-b23f-12875c74ae69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_dialogues = []\n",
    "\n",
    "for dialogue in dialogues:\n",
    "    dialogue = dialogue.strip()\n",
    "    turns = dialogue.split(SEP)\n",
    "    cleaned_dialogues.append(turns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c3945-b696-48c2-8440-6777b5316bad",
   "metadata": {},
   "source": [
    "#### Generate Token IDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e5aa5d9-b60e-4738-aead-2139178e0a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c262685-f523-4ca5-88ae-1ed20607c5df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8939/8939 [00:10<00:00, 858.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 88.7 ms, total: 10.4 s\n",
      "Wall time: 10.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for dialogue in tqdm(cleaned_dialogues):\n",
    "    dialogue_ids = []\n",
    "    for utterance in dialogue:\n",
    "        tokens = tokenizer.tokenize(utterance)\n",
    "        ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        dialogue_ids.append(ids)\n",
    "    token_ids.append(dialogue_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32655c88-a761-4d6d-9860-da03fec6c4f1",
   "metadata": {},
   "source": [
    "#### Generate Token Type IDs and Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "468e3dc1-2b7d-40fd-aab1-13a6d38a9f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bos_id = vocab['<|startoftext|>']\n",
    "eos_id = vocab['<|endoftext|>']\n",
    "speaker_1_id = vocab['<|speaker-1|>']\n",
    "speaker_2_id = vocab['<|speaker-2|>']\n",
    "mask = vocab['<|mask|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94567a9d-236b-4887-97a8-acbb2ad7eb8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8939/8939 [00:00<00:00, 41975.96it/s]\n"
     ]
    }
   ],
   "source": [
    "dialogues_with_speaker_ids = []\n",
    "\n",
    "for dialogue in tqdm(token_ids):\n",
    "    utterances_with_speaker_ids = []\n",
    "    for i, utterance in enumerate(dialogue):\n",
    "        if i%2 == 0:\n",
    "            utterances_with_speaker_ids.append([speaker_1_id] + utterance)  # Speaker 1: User\n",
    "        else:\n",
    "            utterances_with_speaker_ids.append([speaker_2_id] + utterance)  # Speaker 2: Bot\n",
    "            \n",
    "    dialogues_with_speaker_ids.append(utterances_with_speaker_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "008eb94f-cfe7-415c-9c78-d2e016dc196c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8939/8939 [00:00<00:00, 19940.22it/s]\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "for dialogue in tqdm(dialogues_with_speaker_ids):\n",
    "    n = len(dialogue)\n",
    "    for i in range(2, n+1, 2):\n",
    "        turn = dialogue[:i]\n",
    "        input_ids.append([bos_id] + list(chain.from_iterable(turn)) + [eos_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b61e4-3417-4fb5-8882-79b4b12e2b6d",
   "metadata": {},
   "source": [
    "##### Generate Token Type IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcc932bc-0d38-40dc-a49f-3144cdea15fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65719/65719 [00:01<00:00, 44884.18it/s]\n"
     ]
    }
   ],
   "source": [
    "token_type_ids = []\n",
    "\n",
    "for turn in tqdm(input_ids):\n",
    "    turn_token_type_ids = []\n",
    "    type_id = speaker_1_id\n",
    "    for token in turn:\n",
    "        if token == speaker_1_id:\n",
    "            type_id = speaker_1_id\n",
    "            turn_token_type_ids.append(type_id)\n",
    "        elif token == speaker_2_id:\n",
    "            type_id = speaker_2_id\n",
    "            turn_token_type_ids.append(type_id)\n",
    "        else:\n",
    "            turn_token_type_ids.append(type_id) \n",
    "            \n",
    "    token_type_ids.append(turn_token_type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756e28a-e78c-4a9e-8505-85bbef32785b",
   "metadata": {},
   "source": [
    "##### Generate Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2415eb8c-013a-4fc9-b49a-32fc0ec5dd64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mask_except_reply(turn, speaker_2_id):\n",
    "    last_index = -1\n",
    "    for i in range(len(turn) - 1, -1, -1):\n",
    "        if turn[i] == speaker_2_id:\n",
    "            last_index = i\n",
    "            break\n",
    "    for i in range(last_index):\n",
    "        turn[i] = mask\n",
    "    return turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e896bfb-f27b-4bac-b375-90724d71d055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65719/65719 [00:00<00:00, 206130.45it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "for turn in tqdm(input_ids):\n",
    "    turn_labels = mask_except_reply(turn, speaker_2_id)\n",
    "    labels.append(turn_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf1602b-2818-4dfd-a1a6-85eb647baa3a",
   "metadata": {},
   "source": [
    "#### Pad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b55713f0-0747-4b50-90c1-07f244a15e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ids_tensor = []\n",
    "\n",
    "for input_id_turn in input_ids:\n",
    "    input_ids_tensor.append(torch.LongTensor(input_id_turn))\n",
    "input_ids_tensor = torch.nn.utils.rnn.pad_sequence(input_ids_tensor, batch_first=True, padding_value=eos_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed040303-788e-44a7-89e2-514963d399e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_type_ids_tensor = []\n",
    "\n",
    "for token_type_id_turn in token_type_ids:\n",
    "    token_type_ids_tensor.append(torch.LongTensor(token_type_id_turn))\n",
    "token_type_ids_tensor = torch.nn.utils.rnn.pad_sequence(token_type_ids_tensor, batch_first=True, padding_value=eos_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51eb3d4e-cb2d-4432-897c-588837e708e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_tensor = []\n",
    "\n",
    "for label_turn in labels:\n",
    "    labels_tensor.append(torch.LongTensor(label_turn))\n",
    "labels_tensor = torch.nn.utils.rnn.pad_sequence(labels_tensor, batch_first=True, padding_value=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8c4a983-2149-4f02-ba9a-c05c1d21a96e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([65719, 557])\n",
      "Token Type IDs shape: torch.Size([65719, 557])\n",
      "Labels shape: torch.Size([65719, 557])\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Input IDs shape: {input_ids_tensor.shape}')\n",
    "logger.info(f'Token Type IDs shape: {token_type_ids_tensor.shape}')\n",
    "logger.info(f'Labels shape: {labels_tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225c9dd-affc-4dbb-9745-6af849d93c43",
   "metadata": {},
   "source": [
    "#### Create HuggingFace dataset and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47edfbfb-f392-498c-b691-5dcb3802598b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HF dataset: Dataset({\n",
      "    features: ['input_ids', 'token_type_ids', 'labels'],\n",
      "    num_rows: 65719\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data_dict = {'input_ids': input_ids_tensor, \n",
    "             'token_type_ids': token_type_ids_tensor, \n",
    "             'labels': labels_tensor}\n",
    "hf_dataset = datasets.Dataset.from_dict(data_dict)\n",
    "logger.info(f'HF dataset: {hf_dataset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca4678-bc39-4fce-85f7-bc4d1684b0a5",
   "metadata": {},
   "source": [
    "##### Split dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ed6f60b-07c9-40fd-a086-f2f6c9408b20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data splits: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'labels'],\n",
      "        num_rows: 59147\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'labels'],\n",
      "        num_rows: 6572\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_validation_test = hf_dataset.train_test_split(shuffle=True, seed=123, test_size=0.1)\n",
    "data_splits = DatasetDict({'train': train_validation_test['train'],  \n",
    "                           'validation': train_validation_test['test']})\n",
    "logger.info(f'Data splits: {data_splits}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76961a6-38d9-4c87-9259-54f714da0307",
   "metadata": {},
   "source": [
    "##### Save data splits to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c202607-b252-4228-9b07-af04af2b1723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 60/60 [00:04<00:00, 13.16ba/s]\n",
      "Flattening the indices: 100%|██████████| 7/7 [00:00<00:00, 13.95ba/s]                           \n",
      "                                                                                              \r"
     ]
    }
   ],
   "source": [
    "data_splits.save_to_disk('./data/tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c301558-0011-4059-8237-1bf6da4dfc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86fff2-dc46-4ca2-98ae-cfc9518bae29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.12 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.12-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
