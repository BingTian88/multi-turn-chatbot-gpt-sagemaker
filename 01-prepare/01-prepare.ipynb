{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a99ae50-4191-4f27-9585-d998c08dc4e9",
   "metadata": {},
   "source": [
    "##### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dabb2f1-56e1-4fa5-bfd8-cd21b85c6682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "!pip install torch==1.12.1+cu113\n",
    "!pip install transformers==4.26.1\n",
    "!pip install datasets==2.9.0\n",
    "!pip install pandas==1.5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6369d40b-8f2a-46db-a491-62a110e4d8db",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d90638-0932-49cc-9188-94b97da980d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import DatasetDict\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import transformers \n",
    "import datasets\n",
    "import logging\n",
    "import pandas\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5b603f-225d-42c5-8c30-a16194f5d2f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2536e890-6119-492a-bbd1-c97d3991e33d",
   "metadata": {},
   "source": [
    "##### Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2e9ab5-4d0e-4d52-a75b-b6876a1439d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b1b115-a2b6-4ce8-9a0b-3ba1c309eac7",
   "metadata": {},
   "source": [
    "##### Log versions of dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49483a10-6df3-4f46-b555-4068edadb2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using transformers version: 4.26.1]\n",
      "[Using datasets version: 2.9.0]\n",
      "[Using pandas version: 1.5.3]\n",
      "[Using torch version: 1.12.1+cu113]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using transformers version: {transformers.__version__}]')\n",
    "logger.info(f'[Using datasets version: {datasets.__version__}]')\n",
    "logger.info(f'[Using pandas version: {pandas.__version__}]')\n",
    "logger.info(f'[Using torch version: {torch.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd54762-27d8-4b07-8b33-486eafdb04c0",
   "metadata": {},
   "source": [
    "#### Load GPT-Neo tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97cd90cf-a011-4788-aa08-98f3c6426ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 560/560 [00:00<00:00, 78.9kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.01k/1.01k [00:00<00:00, 143kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 83.0MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 52.8MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 357/357 [00:00<00:00, 159kB/s]\n",
      "GPT2TokenizerFast(name_or_path='EleutherAI/gpt-neo-125M', vocab_size=50257, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True)})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "logger.info(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0c24194-1d85-4d1f-8286-144079f4337f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc1cce-f980-409d-aabf-7f809978b0f2",
   "metadata": {},
   "source": [
    "##### Add special tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b35fb4b1-6c0b-4d73-ba34-ecfcfed24811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "special_tokens = {\n",
    "    'bos_token': '<|startoftext|>',\n",
    "    'additional_special_tokens': ['<|speaker-1|>', '<|speaker-2|>', '<|pad|>', '<|mask|>']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad1e7301-cc2f-48e1-b452-10b1d03ccddb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50262"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = tokenizer.add_special_tokens(special_tokens)\n",
    "vocab = tokenizer.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d248514-d058-4675-9daf-f4f8b7440c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='EleutherAI/gpt-neo-125M', vocab_size=50257, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|startoftext|>', 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'additional_special_tokens': ['<|speaker-1|>', '<|speaker-2|>', '<|pad|>', '<|mask|>']})\n"
     ]
    }
   ],
   "source": [
    "logger.info(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb19e327-e72f-46ee-8e83-703779b05bb4",
   "metadata": {},
   "source": [
    "#### Load dialogues dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d17ef6-2db9-460e-ae57-61f7dbe6c010",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.&lt;&gt;Well, I thought we'd start with pronunciation, if that's okay with you.&lt;&gt;Not the hacking and gagging and spitting part.  Please.&lt;&gt;Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You're asking me out.  That's so cute. What's your name again?&lt;&gt;Forget it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No, no, it's my fault -- we didn't have a proper introduction ---&lt;&gt;Cameron.&lt;&gt;The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.&lt;&gt;Seems like she could get a date easy enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why?&lt;&gt;Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.&lt;&gt;That's a shame.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gosh, if only we could find Kat a boyfriend...&lt;&gt;Let me see what I can do.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                             dialogue\n",
       "0  Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.<>Well, I thought we'd start with pronunciation, if that's okay with you.<>Not the hacking and gagging and spitting part.  Please.<>Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
       "1                                                                                                                                                                                                                                                                          You're asking me out.  That's so cute. What's your name again?<>Forget it.\n",
       "2                                                                                          No, no, it's my fault -- we didn't have a proper introduction ---<>Cameron.<>The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.<>Seems like she could get a date easy enough...\n",
       "3                                                                                                                                                                                        Why?<>Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.<>That's a shame.\n",
       "4                                                                                                                                                                                                                                                                           Gosh, if only we could find Kat a boyfriend...<>Let me see what I can do."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/dialogues.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7c14f3e-c801-4b98-94f1-e4e4f10bc6df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dialogue    83097\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b2f353-281b-4f70-8e78-81b5b84837dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dialogues = df['dialogue'].tolist()\n",
    "SEP = '<>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c979d9a1-a4ed-4709-b23f-12875c74ae69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_dialogues = []\n",
    "\n",
    "for dialogue in dialogues:\n",
    "    dialogue = dialogue.strip()\n",
    "    turns = dialogue.split(SEP)\n",
    "    cleaned_dialogues.append(turns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c3945-b696-48c2-8440-6777b5316bad",
   "metadata": {},
   "source": [
    "#### Generate Token IDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e5aa5d9-b60e-4738-aead-2139178e0a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c262685-f523-4ca5-88ae-1ed20607c5df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83097/83097 [00:25<00:00, 3304.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 s, sys: 168 ms, total: 25.2 s\n",
      "Wall time: 25.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for dialogue in tqdm(cleaned_dialogues):\n",
    "    dialogue_ids = []\n",
    "    for utterance in dialogue:\n",
    "        tokens = tokenizer.tokenize(utterance)\n",
    "        ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        dialogue_ids.append(ids)\n",
    "    token_ids.append(dialogue_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32655c88-a761-4d6d-9860-da03fec6c4f1",
   "metadata": {},
   "source": [
    "#### Generate Token Type IDs and Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "468e3dc1-2b7d-40fd-aab1-13a6d38a9f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bos_id = vocab['<|startoftext|>']\n",
    "eos_id = vocab['<|endoftext|>']\n",
    "speaker_1_id = vocab['<|speaker-1|>']\n",
    "speaker_2_id = vocab['<|speaker-2|>']\n",
    "mask = vocab['<|mask|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94567a9d-236b-4887-97a8-acbb2ad7eb8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83097/83097 [00:00<00:00, 129592.49it/s]\n"
     ]
    }
   ],
   "source": [
    "dialogues_with_speaker_ids = []\n",
    "\n",
    "for dialogue in tqdm(token_ids):\n",
    "    utterances_with_speaker_ids = []\n",
    "    for i, utterance in enumerate(dialogue):\n",
    "        if i%2 == 0:\n",
    "            utterances_with_speaker_ids.append([speaker_1_id] + utterance)  # Speaker 1: User\n",
    "        else:\n",
    "            utterances_with_speaker_ids.append([speaker_2_id] + utterance)  # Speaker 2: Bot\n",
    "            \n",
    "    dialogues_with_speaker_ids.append(utterances_with_speaker_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "008eb94f-cfe7-415c-9c78-d2e016dc196c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83097/83097 [00:00<00:00, 121147.62it/s]\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "for dialogue in tqdm(dialogues_with_speaker_ids):\n",
    "    n = len(dialogue)\n",
    "    for i in range(2, n+1, 2):\n",
    "        turn = dialogue[:i]\n",
    "        input_ids.append([bos_id] + list(chain.from_iterable(turn)) + [eos_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b61e4-3417-4fb5-8882-79b4b12e2b6d",
   "metadata": {},
   "source": [
    "##### Generate Token Type IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcc932bc-0d38-40dc-a49f-3144cdea15fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138135/138135 [00:01<00:00, 90155.47it/s]\n"
     ]
    }
   ],
   "source": [
    "token_type_ids = []\n",
    "\n",
    "for turn in tqdm(input_ids):\n",
    "    turn_token_type_ids = []\n",
    "    type_id = speaker_1_id\n",
    "    for token in turn:\n",
    "        if token == speaker_1_id:\n",
    "            type_id = speaker_1_id\n",
    "            turn_token_type_ids.append(type_id)\n",
    "        elif token == speaker_2_id:\n",
    "            type_id = speaker_2_id\n",
    "            turn_token_type_ids.append(type_id)\n",
    "        else:\n",
    "            turn_token_type_ids.append(type_id) \n",
    "            \n",
    "    token_type_ids.append(turn_token_type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756e28a-e78c-4a9e-8505-85bbef32785b",
   "metadata": {},
   "source": [
    "##### Generate Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2415eb8c-013a-4fc9-b49a-32fc0ec5dd64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mask_except_reply(turn, speaker_2_id):\n",
    "    last_index = -1\n",
    "    for i in range(len(turn) - 1, -1, -1):\n",
    "        if turn[i] == speaker_2_id:\n",
    "            last_index = i\n",
    "            break\n",
    "    for i in range(last_index):\n",
    "        turn[i] = mask\n",
    "    return turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e896bfb-f27b-4bac-b375-90724d71d055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138135/138135 [00:00<00:00, 318535.03it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "for turn in tqdm(input_ids):\n",
    "    turn_labels = mask_except_reply(turn, speaker_2_id)\n",
    "    labels.append(turn_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf1602b-2818-4dfd-a1a6-85eb647baa3a",
   "metadata": {},
   "source": [
    "#### Pad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b55713f0-0747-4b50-90c1-07f244a15e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ids_tensor = []\n",
    "\n",
    "for input_id_turn in input_ids:\n",
    "    input_ids_tensor.append(torch.LongTensor(input_id_turn))\n",
    "input_ids_tensor = torch.nn.utils.rnn.pad_sequence(input_ids_tensor, batch_first=True, padding_value=eos_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed040303-788e-44a7-89e2-514963d399e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_type_ids_tensor = []\n",
    "\n",
    "for token_type_id_turn in token_type_ids:\n",
    "    token_type_ids_tensor.append(torch.LongTensor(token_type_id_turn))\n",
    "token_type_ids_tensor = torch.nn.utils.rnn.pad_sequence(token_type_ids_tensor, batch_first=True, padding_value=eos_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51eb3d4e-cb2d-4432-897c-588837e708e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_tensor = []\n",
    "\n",
    "for label_turn in labels:\n",
    "    labels_tensor.append(torch.LongTensor(label_turn))\n",
    "labels_tensor = torch.nn.utils.rnn.pad_sequence(labels_tensor, batch_first=True, padding_value=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8c4a983-2149-4f02-ba9a-c05c1d21a96e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([138135, 1579])\n",
      "Token Type IDs shape: torch.Size([138135, 1579])\n",
      "Labels shape: torch.Size([138135, 1579])\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Input IDs shape: {input_ids_tensor.shape}')\n",
    "logger.info(f'Token Type IDs shape: {token_type_ids_tensor.shape}')\n",
    "logger.info(f'Labels shape: {labels_tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225c9dd-affc-4dbb-9745-6af849d93c43",
   "metadata": {},
   "source": [
    "#### Create HuggingFace dataset and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47edfbfb-f392-498c-b691-5dcb3802598b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HF dataset: Dataset({\n",
      "    features: ['input_ids', 'token_type_ids', 'labels'],\n",
      "    num_rows: 138135\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data_dict = {'input_ids': input_ids_tensor, \n",
    "             'token_type_ids': token_type_ids_tensor, \n",
    "             'labels': labels_tensor}\n",
    "hf_dataset = datasets.Dataset.from_dict(data_dict)\n",
    "logger.info(f'HF dataset: {hf_dataset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca4678-bc39-4fce-85f7-bc4d1684b0a5",
   "metadata": {},
   "source": [
    "##### Split dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ed6f60b-07c9-40fd-a086-f2f6c9408b20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data splits: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'labels'],\n",
      "        num_rows: 124321\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'labels'],\n",
      "        num_rows: 13814\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_validation_test = hf_dataset.train_test_split(shuffle=True, seed=123, test_size=0.1)\n",
    "data_splits = DatasetDict({'train': train_validation_test['train'],  \n",
    "                           'validation': train_validation_test['test']})\n",
    "logger.info(f'Data splits: {data_splits}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76961a6-38d9-4c87-9259-54f714da0307",
   "metadata": {},
   "source": [
    "##### Save data splits to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c202607-b252-4228-9b07-af04af2b1723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 125/125 [00:12<00:00, 10.32ba/s]\n",
      "Flattening the indices: 100%|██████████| 14/14 [00:01<00:00,  9.95ba/s]                          \n",
      "                                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_splits.save_to_disk('./data/tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c301558-0011-4059-8237-1bf6da4dfc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.12 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.12-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
