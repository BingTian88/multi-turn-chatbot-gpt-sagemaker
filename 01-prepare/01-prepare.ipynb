{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a99ae50-4191-4f27-9585-d998c08dc4e9",
   "metadata": {},
   "source": [
    "##### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dabb2f1-56e1-4fa5-bfd8-cd21b85c6682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install torch==1.12.1+cu113\n",
    "!pip install transformers==4.26.1\n",
    "!pip install datasets==2.9.0\n",
    "!pip install pandas==1.5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6369d40b-8f2a-46db-a491-62a110e4d8db",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d90638-0932-49cc-9188-94b97da980d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import DatasetDict\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import transformers \n",
    "import numpy as np\n",
    "import datasets\n",
    "import logging\n",
    "import pandas\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5b603f-225d-42c5-8c30-a16194f5d2f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2536e890-6119-492a-bbd1-c97d3991e33d",
   "metadata": {},
   "source": [
    "##### Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2e9ab5-4d0e-4d52-a75b-b6876a1439d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b1b115-a2b6-4ce8-9a0b-3ba1c309eac7",
   "metadata": {},
   "source": [
    "##### Log versions of dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49483a10-6df3-4f46-b555-4068edadb2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using transformers version: 4.26.1]\n",
      "[Using datasets version: 2.9.0]\n",
      "[Using pandas version: 1.5.3]\n",
      "[Using torch version: 1.12.1+cu113]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using transformers version: {transformers.__version__}]')\n",
    "logger.info(f'[Using datasets version: {datasets.__version__}]')\n",
    "logger.info(f'[Using pandas version: {pandas.__version__}]')\n",
    "logger.info(f'[Using torch version: {torch.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd54762-27d8-4b07-8b33-486eafdb04c0",
   "metadata": {},
   "source": [
    "#### Load GPT-Neo tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97cd90cf-a011-4788-aa08-98f3c6426ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='EleutherAI/gpt-neo-125M', vocab_size=50257, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True)})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "logger.info(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0c24194-1d85-4d1f-8286-144079f4337f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc1cce-f980-409d-aabf-7f809978b0f2",
   "metadata": {},
   "source": [
    "##### Add special tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b35fb4b1-6c0b-4d73-ba34-ecfcfed24811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "special_tokens = {\n",
    "    'bos_token': '<|startoftext|>',\n",
    "    'additional_special_tokens': ['<|speaker-1|>', '<|speaker-2|>', '<|pad|>', '<|mask|>']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad1e7301-cc2f-48e1-b452-10b1d03ccddb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50262"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = tokenizer.add_special_tokens(special_tokens)\n",
    "vocab = tokenizer.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d248514-d058-4675-9daf-f4f8b7440c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='EleutherAI/gpt-neo-125M', vocab_size=50257, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|startoftext|>', 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'additional_special_tokens': ['<|speaker-1|>', '<|speaker-2|>', '<|pad|>', '<|mask|>']})\n"
     ]
    }
   ],
   "source": [
    "logger.info(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb19e327-e72f-46ee-8e83-703779b05bb4",
   "metadata": {},
   "source": [
    "#### Load dialogues dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d17ef6-2db9-460e-ae57-61f7dbe6c010",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i got high once i was home alone. i smoked a lot of weed and i was really paranoid&lt;&gt;i was feeling rather anxious the other day because i smoked a ton of pot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i accidentally stepped on someone's toe at the grocery store and they really looked in pain&lt;&gt;of course! i probably apologized 20 times. i felt so guilty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am so elated. i am going on a vacation tomorrow.&lt;&gt;i am going to north korea.. i can't wait!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am nina and i have an apartment in new york&lt;&gt;hi nina , my name is rob . i fix roofs for a living .&lt;&gt;i am twenty one years of age and i love roses as my fave flower .&lt;&gt;that is cool you are twenty one . i enjoy drinking beer when i get home from work&lt;&gt;my small black and white cat is just so playful and loves to mess around&lt;&gt;when i was in highschool i was quarterback for the football team .&lt;&gt;i bet you did well in that sport&lt;&gt;yes . i love eating well done steaks so i am big and muscular .&lt;&gt;wow ! steak and good looking i bet . lol&lt;&gt;and i drive a really nice chevy truck ! i have it lifted since i go off roading&lt;&gt;what else do you do for fun ?&lt;&gt;i enjoy running . i compete in a marathon at least once a year .&lt;&gt;oh how far do you run&lt;&gt;most days i run 5 miles in the morning&lt;&gt;some days i walk from 6 7 miles a day&lt;&gt;where do you like to walk ?&lt;&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi i am tom and i am eating my favorite thing , pizza&lt;&gt;hi . pizza sounds good . i am nervous , proposing to my girlfriend tonight .&lt;&gt;oh awesome you should take her to an italian restaurant who does not love that&lt;&gt;so true . we already bought a house and she is 6 months pregnant so i think she will accept .&lt;&gt;wow ! ! ! that is so cool , i better keep trying to watch what i eat maybe i will find someone&lt;&gt;you will . we went to school together i got my college diploma just last week .&lt;&gt;congrats i got mines a few years after moving here i am from east asia&lt;&gt;i would love to visit there . never really traveled , guess we wo not now .&lt;&gt;well its never too late to explore&lt;&gt;our house is near her parents , that is what makes me most nervous about things .&lt;&gt;well that means you will have help when the baby arrives&lt;&gt;so true . anything else interesting you would like to share ?&lt;&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     dialogue\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                i got high once i was home alone. i smoked a lot of weed and i was really paranoid<>i was feeling rather anxious the other day because i smoked a ton of pot\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   i accidentally stepped on someone's toe at the grocery store and they really looked in pain<>of course! i probably apologized 20 times. i felt so guilty.\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               i am so elated. i am going on a vacation tomorrow.<>i am going to north korea.. i can't wait!\n",
       "3                                i am nina and i have an apartment in new york<>hi nina , my name is rob . i fix roofs for a living .<>i am twenty one years of age and i love roses as my fave flower .<>that is cool you are twenty one . i enjoy drinking beer when i get home from work<>my small black and white cat is just so playful and loves to mess around<>when i was in highschool i was quarterback for the football team .<>i bet you did well in that sport<>yes . i love eating well done steaks so i am big and muscular .<>wow ! steak and good looking i bet . lol<>and i drive a really nice chevy truck ! i have it lifted since i go off roading<>what else do you do for fun ?<>i enjoy running . i compete in a marathon at least once a year .<>oh how far do you run<>most days i run 5 miles in the morning<>some days i walk from 6 7 miles a day<>where do you like to walk ?<>\n",
       "4  hi i am tom and i am eating my favorite thing , pizza<>hi . pizza sounds good . i am nervous , proposing to my girlfriend tonight .<>oh awesome you should take her to an italian restaurant who does not love that<>so true . we already bought a house and she is 6 months pregnant so i think she will accept .<>wow ! ! ! that is so cool , i better keep trying to watch what i eat maybe i will find someone<>you will . we went to school together i got my college diploma just last week .<>congrats i got mines a few years after moving here i am from east asia<>i would love to visit there . never really traveled , guess we wo not now .<>well its never too late to explore<>our house is near her parents , that is what makes me most nervous about things .<>well that means you will have help when the baby arrives<>so true . anything else interesting you would like to share ?<>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/dialogues.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7c14f3e-c801-4b98-94f1-e4e4f10bc6df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dialogue    121703\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b2f353-281b-4f70-8e78-81b5b84837dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dialogues = df['dialogue'].tolist()\n",
    "SEP = '<>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4e51ce5-0b9a-4125-8b4d-198373a86d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average dialogue length = 252\n"
     ]
    }
   ],
   "source": [
    "dialogue_lengths = []\n",
    "\n",
    "for dialogue in dialogues:\n",
    "    dialogue = dialogue.strip()\n",
    "    dialogue_lengths.append(len(dialogue))\n",
    "\n",
    "mean_dialogue_len = np.mean(dialogue_lengths)\n",
    "logger.info(f'Average dialogue length = {int(mean_dialogue_len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c979d9a1-a4ed-4709-b23f-12875c74ae69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_dialogues = []\n",
    "MAX_LEN = (mean_dialogue_len * 4)\n",
    "MIN_TURNS = 2\n",
    "\n",
    "for dialogue in dialogues:\n",
    "    dialogue = dialogue.strip()\n",
    "    turns = dialogue.split(SEP)\n",
    "    if len(dialogue) <= MAX_LEN and len(turns) > MIN_TURNS:\n",
    "        cleaned_dialogues.append(turns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c3945-b696-48c2-8440-6777b5316bad",
   "metadata": {},
   "source": [
    "#### Generate Token IDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e5aa5d9-b60e-4738-aead-2139178e0a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c262685-f523-4ca5-88ae-1ed20607c5df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19591/19591 [00:15<00:00, 1231.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.9 s, sys: 109 ms, total: 16 s\n",
      "Wall time: 15.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for dialogue in tqdm(cleaned_dialogues):\n",
    "    dialogue_ids = []\n",
    "    for utterance in dialogue:\n",
    "        tokens = tokenizer.tokenize(utterance)\n",
    "        ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        dialogue_ids.append(ids)\n",
    "    token_ids.append(dialogue_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32655c88-a761-4d6d-9860-da03fec6c4f1",
   "metadata": {},
   "source": [
    "#### Generate Token Type IDs and Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "468e3dc1-2b7d-40fd-aab1-13a6d38a9f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bos_id = vocab['<|startoftext|>']\n",
    "eos_id = vocab['<|endoftext|>']\n",
    "speaker_1_id = vocab['<|speaker-1|>']\n",
    "speaker_2_id = vocab['<|speaker-2|>']\n",
    "mask = vocab['<|mask|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94567a9d-236b-4887-97a8-acbb2ad7eb8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19591/19591 [00:00<00:00, 44763.62it/s]\n"
     ]
    }
   ],
   "source": [
    "dialogues_with_speaker_ids = []\n",
    "\n",
    "for dialogue in tqdm(token_ids):\n",
    "    utterances_with_speaker_ids = []\n",
    "    for i, utterance in enumerate(dialogue):\n",
    "        if i%2 == 0:\n",
    "            utterances_with_speaker_ids.append([speaker_1_id] + utterance)  # Speaker 1: User\n",
    "        else:\n",
    "            utterances_with_speaker_ids.append([speaker_2_id] + utterance)  # Speaker 2: Bot\n",
    "            \n",
    "    dialogues_with_speaker_ids.append(utterances_with_speaker_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "008eb94f-cfe7-415c-9c78-d2e016dc196c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19591/19591 [00:00<00:00, 51444.44it/s]\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "for dialogue in tqdm(dialogues_with_speaker_ids):\n",
    "    n = len(dialogue)\n",
    "    for i in range(2, n+1, 2):\n",
    "        turn = dialogue[:i]\n",
    "        input_ids.append([bos_id] + list(chain.from_iterable(turn)) + [eos_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b61e4-3417-4fb5-8882-79b4b12e2b6d",
   "metadata": {},
   "source": [
    "##### Generate Token Type IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcc932bc-0d38-40dc-a49f-3144cdea15fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103524/103524 [00:02<00:00, 48638.77it/s]\n"
     ]
    }
   ],
   "source": [
    "token_type_ids = []\n",
    "\n",
    "for turn in tqdm(input_ids):\n",
    "    turn_token_type_ids = []\n",
    "    type_id = speaker_1_id\n",
    "    for token in turn:\n",
    "        if token == speaker_1_id:\n",
    "            type_id = speaker_1_id\n",
    "            turn_token_type_ids.append(type_id)\n",
    "        elif token == speaker_2_id:\n",
    "            type_id = speaker_2_id\n",
    "            turn_token_type_ids.append(type_id)\n",
    "        else:\n",
    "            turn_token_type_ids.append(type_id) \n",
    "            \n",
    "    token_type_ids.append(turn_token_type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756e28a-e78c-4a9e-8505-85bbef32785b",
   "metadata": {},
   "source": [
    "##### Generate Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2415eb8c-013a-4fc9-b49a-32fc0ec5dd64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mask_except_reply(turn, speaker_2_id):\n",
    "    last_index = -1\n",
    "    for i in range(len(turn) - 1, -1, -1):\n",
    "        if turn[i] == speaker_2_id:\n",
    "            last_index = i\n",
    "            break\n",
    "    for i in range(last_index):\n",
    "        turn[i] = mask\n",
    "    return turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e896bfb-f27b-4bac-b375-90724d71d055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103524/103524 [00:00<00:00, 246525.83it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "for turn in tqdm(input_ids):\n",
    "    turn_labels = mask_except_reply(turn, speaker_2_id)\n",
    "    labels.append(turn_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf1602b-2818-4dfd-a1a6-85eb647baa3a",
   "metadata": {},
   "source": [
    "#### Pad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b55713f0-0747-4b50-90c1-07f244a15e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ids_tensor = []\n",
    "\n",
    "for input_id_turn in input_ids:\n",
    "    input_ids_tensor.append(torch.LongTensor(input_id_turn))\n",
    "input_ids_tensor = torch.nn.utils.rnn.pad_sequence(input_ids_tensor, \n",
    "                                                   batch_first=True, \n",
    "                                                   padding_value=eos_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed040303-788e-44a7-89e2-514963d399e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_type_ids_tensor = []\n",
    "\n",
    "for token_type_id_turn in token_type_ids:\n",
    "    token_type_ids_tensor.append(torch.LongTensor(token_type_id_turn))\n",
    "token_type_ids_tensor = torch.nn.utils.rnn.pad_sequence(token_type_ids_tensor, \n",
    "                                                        batch_first=True, \n",
    "                                                        padding_value=eos_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51eb3d4e-cb2d-4432-897c-588837e708e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_tensor = []\n",
    "\n",
    "for label_turn in labels:\n",
    "    labels_tensor.append(torch.LongTensor(label_turn))\n",
    "labels_tensor = torch.nn.utils.rnn.pad_sequence(labels_tensor, \n",
    "                                                batch_first=True, \n",
    "                                                padding_value=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8c4a983-2149-4f02-ba9a-c05c1d21a96e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([103524, 282])\n",
      "Token Type IDs shape: torch.Size([103524, 282])\n",
      "Labels shape: torch.Size([103524, 282])\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Input IDs shape: {input_ids_tensor.shape}')\n",
    "logger.info(f'Token Type IDs shape: {token_type_ids_tensor.shape}')\n",
    "logger.info(f'Labels shape: {labels_tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225c9dd-affc-4dbb-9745-6af849d93c43",
   "metadata": {},
   "source": [
    "#### Create HuggingFace dataset and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47edfbfb-f392-498c-b691-5dcb3802598b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HF dataset: Dataset({\n",
      "    features: ['input_ids', 'token_type_ids', 'labels'],\n",
      "    num_rows: 103524\n",
      "})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.01 s, sys: 1.35 s, total: 4.36 s\n",
      "Wall time: 4.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_dict = {'input_ids': input_ids_tensor, \n",
    "             'token_type_ids': token_type_ids_tensor, \n",
    "             'labels': labels_tensor}\n",
    "hf_dataset = datasets.Dataset.from_dict(data_dict)\n",
    "logger.info(f'HF dataset: {hf_dataset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca4678-bc39-4fce-85f7-bc4d1684b0a5",
   "metadata": {},
   "source": [
    "##### Split dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ed6f60b-07c9-40fd-a086-f2f6c9408b20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data splits: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'labels'],\n",
      "        num_rows: 93171\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'labels'],\n",
      "        num_rows: 10353\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_validation_test = hf_dataset.train_test_split(shuffle=True, \n",
    "                                                    seed=123, \n",
    "                                                    test_size=0.1)\n",
    "data_splits = DatasetDict({'train': train_validation_test['train'],  \n",
    "                           'validation': train_validation_test['test']})\n",
    "logger.info(f'Data splits: {data_splits}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76961a6-38d9-4c87-9259-54f714da0307",
   "metadata": {},
   "source": [
    "##### Save data splits to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c202607-b252-4228-9b07-af04af2b1723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 94/94 [00:05<00:00, 16.11ba/s]\n",
      "Flattening the indices: 100%|██████████| 11/11 [00:00<00:00, 19.04ba/s]                         \n",
      "                                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_splits.save_to_disk('./data/tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86fff2-dc46-4ca2-98ae-cfc9518bae29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.g4dn.12xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.12 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.12-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
